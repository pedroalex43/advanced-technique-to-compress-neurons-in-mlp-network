{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ecba23-53db-4e0c-b571-97b33e7a9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class SensorNeuron(nn.Module):\n",
    "    def __init__(self, input_size, dataset_samples, threshold=0.5):\n",
    "        super(SensorNeuron, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.dataset_samples = dataset_samples\n",
    "        self.threshold = threshold  # Limiar para sinal forte\n",
    "        self.sensory_db = self.initialize_sensory_neurons()  # Banco de dados sensorial\n",
    "        self.consolidation_counter = [0] * input_size  # Contadores de consolidação\n",
    "    \n",
    "    def initialize_sensory_neurons(self):\n",
    "        sensory_neurons = []\n",
    "        for _ in range(self.input_size):\n",
    "            random_sample = random.choice(self.dataset_samples)\n",
    "            sensory_neurons.append(random.choice(random_sample))  # Neurônios inicializados com dados aleatórios\n",
    "        return torch.tensor(sensory_neurons).float()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.float()  # Garantir tipo correto de entrada\n",
    "        reinforcement_score = 0  # Inicia o score de reforço\n",
    "        for i in range(self.input_size):\n",
    "            # Calcula a diferença absoluta\n",
    "            diff = torch.abs(x[:, i] - self.sensory_db[i])\n",
    "            \n",
    "            # Verifica se cada elemento no lote é menor que o threshold\n",
    "            signal_strong = diff < self.threshold\n",
    "            \n",
    "            # Verifica se a maioria dos sinais é forte (True)\n",
    "            if signal_strong.all():  # Se todos os valores no lote são menores que o limiar\n",
    "                self.consolidation_counter[i] += 1\n",
    "                reinforcement_score += 1  # Sinal forte encontrado, reforça a informação\n",
    "            else:\n",
    "                self.consolidation_counter[i] -= 1  # Sinal fraco, reduz a consolidação\n",
    "            \n",
    "            # Caso o contador de consolidação seja negativo, atualiza o neurônio\n",
    "            if self.consolidation_counter[i] < 0:\n",
    "                self.sensory_db = self.update_sensory_neuron(self.sensory_db, self.dataset_samples, i)  # Chama a função externa\n",
    "        return x, reinforcement_score\n",
    "    \n",
    "    def update_sensory_neuron(self, sensory_db, dataset_samples, index):\n",
    "        random_sample = random.choice(dataset_samples)\n",
    "        new_value = random.choice(random_sample)\n",
    "        sensory_db[index] = new_value\n",
    "        return sensory_db\n",
    "        \n",
    "    def reinforce_database(self):\n",
    "        # Caso o sinal seja encontrado mais de uma vez, a informação é consolidada no banco de dados permanente\n",
    "        for i in range(self.input_size):\n",
    "            if self.consolidation_counter[i] > 5:  # Exemplo de limiar de consolidação\n",
    "                self.sensory_db[i] = self.sensory_db[i]  # Reforço da informação\n",
    "            elif self.consolidation_counter[i] < -3:\n",
    "                self.update_sensory_neuron(i)  # Atualiza os neurônios com base no contador de consolidação\n",
    "\n",
    "\n",
    "    def process_temp_db(self):\n",
    "        for temp_signal in self.temp_db:\n",
    "            print(f\"temp_signal shape: {temp_signal.shape}\")\n",
    "            print(f\"sensory_db shape: {self.sensory_db.shape}\")\n",
    "\n",
    "            if temp_signal.dim() == 1:\n",
    "                temp_signal = temp_signal.view(1, -1)  # Ajusta a dimensão de temp_signal\n",
    "\n",
    "            if temp_signal.size(1) == self.sensory_db.size(1):\n",
    "                diff = torch.abs(temp_signal - self.sensory_db.unsqueeze(0))  # Adiciona uma dimensão ao sensory_db para comparação\n",
    "                print(f\"Diff shape: {diff.shape}\")\n",
    "            else:\n",
    "                print(f\"Dimensões incompatíveis: temp_signal {temp_signal.size()} vs sensory_db {self.sensory_db.size()}\")\n",
    "\n",
    "class AdvancedMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dataset_samples, threshold=0.5):\n",
    "        super(AdvancedMLP, self).__init__()\n",
    "        self.sensor_neuron = SensorNeuron(input_size=input_size, dataset_samples=dataset_samples, threshold=threshold)  # Neurônios sensoriais\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, reinforcement_score = self.sensor_neuron(x)  # Processamento inicial com neurônios sensoriais\n",
    "        x = F.relu(self.fc1(x))  # Primeira camada de rede neural\n",
    "        x = self.fc2(x)  # Camada final de saída\n",
    "        return F.log_softmax(x, dim=1), reinforcement_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6eed6b1-a1f6-4a65-8a7e-9a343eef70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 1.2228, Accuracy: 13.33%\n",
      "Epoch [2/200], Loss: 1.1977, Accuracy: 20.00%\n",
      "Epoch [3/200], Loss: 1.1701, Accuracy: 20.00%\n",
      "Epoch [4/200], Loss: 1.1450, Accuracy: 20.00%\n",
      "Epoch [5/200], Loss: 1.1234, Accuracy: 20.83%\n",
      "Epoch [6/200], Loss: 1.1028, Accuracy: 20.83%\n",
      "Epoch [7/200], Loss: 1.0846, Accuracy: 22.50%\n",
      "Epoch [8/200], Loss: 1.0629, Accuracy: 23.33%\n",
      "Epoch [9/200], Loss: 1.0421, Accuracy: 24.17%\n",
      "Epoch [10/200], Loss: 1.0188, Accuracy: 29.17%\n",
      "Epoch [11/200], Loss: 1.0024, Accuracy: 35.83%\n",
      "Epoch [12/200], Loss: 0.9849, Accuracy: 44.17%\n",
      "Epoch [13/200], Loss: 0.9648, Accuracy: 53.33%\n",
      "Epoch [14/200], Loss: 0.9466, Accuracy: 57.50%\n",
      "Epoch [15/200], Loss: 0.9264, Accuracy: 60.83%\n",
      "Epoch [16/200], Loss: 0.9060, Accuracy: 62.50%\n",
      "Epoch [17/200], Loss: 0.8900, Accuracy: 62.50%\n",
      "Epoch [18/200], Loss: 0.8764, Accuracy: 63.33%\n",
      "Epoch [19/200], Loss: 0.8600, Accuracy: 63.33%\n",
      "Epoch [20/200], Loss: 0.8431, Accuracy: 64.17%\n",
      "Epoch [21/200], Loss: 0.8226, Accuracy: 65.00%\n",
      "Epoch [22/200], Loss: 0.8037, Accuracy: 70.00%\n",
      "Epoch [23/200], Loss: 0.7910, Accuracy: 70.83%\n",
      "Epoch [24/200], Loss: 0.7808, Accuracy: 75.00%\n",
      "Epoch [25/200], Loss: 0.7586, Accuracy: 77.50%\n",
      "Epoch [26/200], Loss: 0.7450, Accuracy: 79.17%\n",
      "Epoch [27/200], Loss: 0.7351, Accuracy: 79.17%\n",
      "Epoch [28/200], Loss: 0.7220, Accuracy: 80.00%\n",
      "Epoch [29/200], Loss: 0.7068, Accuracy: 81.67%\n",
      "Epoch [30/200], Loss: 0.6893, Accuracy: 81.67%\n",
      "Epoch [31/200], Loss: 0.6759, Accuracy: 81.67%\n",
      "Epoch [32/200], Loss: 0.6736, Accuracy: 83.33%\n",
      "Epoch [33/200], Loss: 0.6516, Accuracy: 85.83%\n",
      "Epoch [34/200], Loss: 0.6457, Accuracy: 85.83%\n",
      "Epoch [35/200], Loss: 0.6383, Accuracy: 85.83%\n",
      "Epoch [36/200], Loss: 0.6218, Accuracy: 85.83%\n",
      "Epoch [37/200], Loss: 0.6028, Accuracy: 85.83%\n",
      "Epoch [38/200], Loss: 0.5912, Accuracy: 85.83%\n",
      "Epoch [39/200], Loss: 0.5884, Accuracy: 85.83%\n",
      "Epoch [40/200], Loss: 0.5775, Accuracy: 85.83%\n",
      "Epoch [41/200], Loss: 0.5663, Accuracy: 85.83%\n",
      "Epoch [42/200], Loss: 0.5572, Accuracy: 85.83%\n",
      "Epoch [43/200], Loss: 0.5566, Accuracy: 85.83%\n",
      "Epoch [44/200], Loss: 0.5475, Accuracy: 85.83%\n",
      "Epoch [45/200], Loss: 0.5348, Accuracy: 85.83%\n",
      "Epoch [46/200], Loss: 0.5303, Accuracy: 85.83%\n",
      "Epoch [47/200], Loss: 0.5168, Accuracy: 85.83%\n",
      "Epoch [48/200], Loss: 0.5079, Accuracy: 85.83%\n",
      "Epoch [49/200], Loss: 0.5077, Accuracy: 85.83%\n",
      "Epoch [50/200], Loss: 0.4967, Accuracy: 85.83%\n",
      "Epoch [51/200], Loss: 0.4883, Accuracy: 85.83%\n",
      "Epoch [52/200], Loss: 0.4875, Accuracy: 85.83%\n",
      "Epoch [53/200], Loss: 0.4751, Accuracy: 85.83%\n",
      "Epoch [54/200], Loss: 0.4815, Accuracy: 85.83%\n",
      "Epoch [55/200], Loss: 0.4664, Accuracy: 85.83%\n",
      "Epoch [56/200], Loss: 0.4612, Accuracy: 85.83%\n",
      "Epoch [57/200], Loss: 0.4608, Accuracy: 85.83%\n",
      "Epoch [58/200], Loss: 0.4496, Accuracy: 86.67%\n",
      "Epoch [59/200], Loss: 0.4508, Accuracy: 86.67%\n",
      "Epoch [60/200], Loss: 0.4414, Accuracy: 86.67%\n",
      "Epoch [61/200], Loss: 0.4413, Accuracy: 86.67%\n",
      "Epoch [62/200], Loss: 0.4279, Accuracy: 86.67%\n",
      "Epoch [63/200], Loss: 0.4311, Accuracy: 86.67%\n",
      "Epoch [64/200], Loss: 0.4199, Accuracy: 86.67%\n",
      "Epoch [65/200], Loss: 0.4153, Accuracy: 87.50%\n",
      "Epoch [66/200], Loss: 0.4143, Accuracy: 87.50%\n",
      "Epoch [67/200], Loss: 0.4061, Accuracy: 87.50%\n",
      "Epoch [68/200], Loss: 0.4008, Accuracy: 87.50%\n",
      "Epoch [69/200], Loss: 0.3954, Accuracy: 87.50%\n",
      "Epoch [70/200], Loss: 0.3995, Accuracy: 87.50%\n",
      "Epoch [71/200], Loss: 0.3905, Accuracy: 87.50%\n",
      "Epoch [72/200], Loss: 0.3876, Accuracy: 87.50%\n",
      "Epoch [73/200], Loss: 0.3888, Accuracy: 87.50%\n",
      "Epoch [74/200], Loss: 0.3860, Accuracy: 87.50%\n",
      "Epoch [75/200], Loss: 0.3765, Accuracy: 87.50%\n",
      "Epoch [76/200], Loss: 0.3711, Accuracy: 88.33%\n",
      "Epoch [77/200], Loss: 0.3683, Accuracy: 88.33%\n",
      "Epoch [78/200], Loss: 0.3676, Accuracy: 88.33%\n",
      "Epoch [79/200], Loss: 0.3589, Accuracy: 88.33%\n",
      "Epoch [80/200], Loss: 0.3587, Accuracy: 88.33%\n",
      "Epoch [81/200], Loss: 0.3513, Accuracy: 88.33%\n",
      "Epoch [82/200], Loss: 0.3507, Accuracy: 88.33%\n",
      "Epoch [83/200], Loss: 0.3474, Accuracy: 88.33%\n",
      "Epoch [84/200], Loss: 0.3422, Accuracy: 88.33%\n",
      "Epoch [85/200], Loss: 0.3452, Accuracy: 89.17%\n",
      "Epoch [86/200], Loss: 0.3412, Accuracy: 89.17%\n",
      "Epoch [87/200], Loss: 0.3378, Accuracy: 89.17%\n",
      "Epoch [88/200], Loss: 0.3389, Accuracy: 90.00%\n",
      "Epoch [89/200], Loss: 0.3326, Accuracy: 90.00%\n",
      "Epoch [90/200], Loss: 0.3207, Accuracy: 90.00%\n",
      "Epoch [91/200], Loss: 0.3247, Accuracy: 90.00%\n",
      "Epoch [92/200], Loss: 0.3206, Accuracy: 90.83%\n",
      "Epoch [93/200], Loss: 0.3169, Accuracy: 90.83%\n",
      "Epoch [94/200], Loss: 0.3175, Accuracy: 90.83%\n",
      "Epoch [95/200], Loss: 0.3141, Accuracy: 90.83%\n",
      "Epoch [96/200], Loss: 0.3123, Accuracy: 90.83%\n",
      "Epoch [97/200], Loss: 0.3030, Accuracy: 90.83%\n",
      "Epoch [98/200], Loss: 0.3042, Accuracy: 90.83%\n",
      "Epoch [99/200], Loss: 0.3055, Accuracy: 90.83%\n",
      "Epoch [100/200], Loss: 0.3046, Accuracy: 90.83%\n",
      "Epoch [101/200], Loss: 0.2986, Accuracy: 90.83%\n",
      "Epoch [102/200], Loss: 0.2982, Accuracy: 90.83%\n",
      "Epoch [103/200], Loss: 0.2999, Accuracy: 91.67%\n",
      "Epoch [104/200], Loss: 0.2942, Accuracy: 91.67%\n",
      "Epoch [105/200], Loss: 0.2962, Accuracy: 91.67%\n",
      "Epoch [106/200], Loss: 0.2846, Accuracy: 91.67%\n",
      "Epoch [107/200], Loss: 0.2832, Accuracy: 91.67%\n",
      "Epoch [108/200], Loss: 0.2794, Accuracy: 91.67%\n",
      "Epoch [109/200], Loss: 0.2744, Accuracy: 92.50%\n",
      "Epoch [110/200], Loss: 0.2716, Accuracy: 93.33%\n",
      "Epoch [111/200], Loss: 0.2779, Accuracy: 93.33%\n",
      "Epoch [112/200], Loss: 0.2766, Accuracy: 93.33%\n",
      "Epoch [113/200], Loss: 0.2737, Accuracy: 93.33%\n",
      "Epoch [114/200], Loss: 0.2691, Accuracy: 93.33%\n",
      "Epoch [115/200], Loss: 0.2723, Accuracy: 93.33%\n",
      "Epoch [116/200], Loss: 0.2644, Accuracy: 93.33%\n",
      "Epoch [117/200], Loss: 0.2635, Accuracy: 93.33%\n",
      "Epoch [118/200], Loss: 0.2562, Accuracy: 93.33%\n",
      "Epoch [119/200], Loss: 0.2596, Accuracy: 93.33%\n",
      "Epoch [120/200], Loss: 0.2533, Accuracy: 92.50%\n",
      "Epoch [121/200], Loss: 0.2551, Accuracy: 92.50%\n",
      "Epoch [122/200], Loss: 0.2601, Accuracy: 93.33%\n",
      "Epoch [123/200], Loss: 0.2527, Accuracy: 93.33%\n",
      "Epoch [124/200], Loss: 0.2490, Accuracy: 93.33%\n",
      "Epoch [125/200], Loss: 0.2498, Accuracy: 93.33%\n",
      "Epoch [126/200], Loss: 0.2442, Accuracy: 93.33%\n",
      "Epoch [127/200], Loss: 0.2434, Accuracy: 93.33%\n",
      "Epoch [128/200], Loss: 0.2406, Accuracy: 94.17%\n",
      "Epoch [129/200], Loss: 0.2442, Accuracy: 94.17%\n",
      "Epoch [130/200], Loss: 0.2381, Accuracy: 94.17%\n",
      "Epoch [131/200], Loss: 0.2378, Accuracy: 94.17%\n",
      "Epoch [132/200], Loss: 0.2318, Accuracy: 94.17%\n",
      "Epoch [133/200], Loss: 0.2332, Accuracy: 94.17%\n",
      "Epoch [134/200], Loss: 0.2309, Accuracy: 94.17%\n",
      "Epoch [135/200], Loss: 0.2303, Accuracy: 94.17%\n",
      "Epoch [136/200], Loss: 0.2237, Accuracy: 94.17%\n",
      "Epoch [137/200], Loss: 0.2248, Accuracy: 94.17%\n",
      "Epoch [138/200], Loss: 0.2254, Accuracy: 94.17%\n",
      "Epoch [139/200], Loss: 0.2167, Accuracy: 94.17%\n",
      "Epoch [140/200], Loss: 0.2192, Accuracy: 95.00%\n",
      "Epoch [141/200], Loss: 0.2189, Accuracy: 95.00%\n",
      "Epoch [142/200], Loss: 0.2192, Accuracy: 95.00%\n",
      "Epoch [143/200], Loss: 0.2150, Accuracy: 95.00%\n",
      "Epoch [144/200], Loss: 0.2136, Accuracy: 95.00%\n",
      "Epoch [145/200], Loss: 0.2197, Accuracy: 95.00%\n",
      "Epoch [146/200], Loss: 0.2056, Accuracy: 95.00%\n",
      "Epoch [147/200], Loss: 0.2101, Accuracy: 95.83%\n",
      "Epoch [148/200], Loss: 0.2053, Accuracy: 95.83%\n",
      "Epoch [149/200], Loss: 0.2030, Accuracy: 95.83%\n",
      "Epoch [150/200], Loss: 0.2027, Accuracy: 95.83%\n",
      "Epoch [151/200], Loss: 0.2008, Accuracy: 95.83%\n",
      "Epoch [152/200], Loss: 0.1960, Accuracy: 95.83%\n",
      "Epoch [153/200], Loss: 0.1995, Accuracy: 95.83%\n",
      "Epoch [154/200], Loss: 0.1940, Accuracy: 95.83%\n",
      "Epoch [155/200], Loss: 0.1931, Accuracy: 95.83%\n",
      "Epoch [156/200], Loss: 0.1947, Accuracy: 95.83%\n",
      "Epoch [157/200], Loss: 0.1902, Accuracy: 95.83%\n",
      "Epoch [158/200], Loss: 0.1864, Accuracy: 95.83%\n",
      "Epoch [159/200], Loss: 0.1890, Accuracy: 95.83%\n",
      "Epoch [160/200], Loss: 0.1890, Accuracy: 95.83%\n",
      "Epoch [161/200], Loss: 0.1814, Accuracy: 95.83%\n",
      "Epoch [162/200], Loss: 0.1818, Accuracy: 95.83%\n",
      "Epoch [163/200], Loss: 0.1823, Accuracy: 95.83%\n",
      "Epoch [164/200], Loss: 0.1828, Accuracy: 95.83%\n",
      "Epoch [165/200], Loss: 0.1767, Accuracy: 95.83%\n",
      "Epoch [166/200], Loss: 0.1754, Accuracy: 95.83%\n",
      "Epoch [167/200], Loss: 0.1795, Accuracy: 95.83%\n",
      "Epoch [168/200], Loss: 0.1704, Accuracy: 95.83%\n",
      "Epoch [169/200], Loss: 0.1747, Accuracy: 95.83%\n",
      "Epoch [170/200], Loss: 0.1672, Accuracy: 95.83%\n",
      "Epoch [171/200], Loss: 0.1762, Accuracy: 95.83%\n",
      "Epoch [172/200], Loss: 0.1667, Accuracy: 95.83%\n",
      "Epoch [173/200], Loss: 0.1677, Accuracy: 95.83%\n",
      "Epoch [174/200], Loss: 0.1678, Accuracy: 95.83%\n",
      "Epoch [175/200], Loss: 0.1668, Accuracy: 95.83%\n",
      "Epoch [176/200], Loss: 0.1643, Accuracy: 95.83%\n",
      "Epoch [177/200], Loss: 0.1581, Accuracy: 95.83%\n",
      "Epoch [178/200], Loss: 0.1600, Accuracy: 95.83%\n",
      "Epoch [179/200], Loss: 0.1601, Accuracy: 95.83%\n",
      "Epoch [180/200], Loss: 0.1613, Accuracy: 95.83%\n",
      "Epoch [181/200], Loss: 0.1569, Accuracy: 95.83%\n",
      "Epoch [182/200], Loss: 0.1616, Accuracy: 95.83%\n",
      "Epoch [183/200], Loss: 0.1520, Accuracy: 95.83%\n",
      "Epoch [184/200], Loss: 0.1507, Accuracy: 95.83%\n",
      "Epoch [185/200], Loss: 0.1516, Accuracy: 95.83%\n",
      "Epoch [186/200], Loss: 0.1502, Accuracy: 95.83%\n",
      "Epoch [187/200], Loss: 0.1516, Accuracy: 95.83%\n",
      "Epoch [188/200], Loss: 0.1458, Accuracy: 95.83%\n",
      "Epoch [189/200], Loss: 0.1490, Accuracy: 96.67%\n",
      "Epoch [190/200], Loss: 0.1462, Accuracy: 96.67%\n",
      "Epoch [191/200], Loss: 0.1452, Accuracy: 96.67%\n",
      "Epoch [192/200], Loss: 0.1474, Accuracy: 96.67%\n",
      "Epoch [193/200], Loss: 0.1449, Accuracy: 96.67%\n",
      "Epoch [194/200], Loss: 0.1405, Accuracy: 96.67%\n",
      "Epoch [195/200], Loss: 0.1384, Accuracy: 96.67%\n",
      "Epoch [196/200], Loss: 0.1403, Accuracy: 96.67%\n",
      "Epoch [197/200], Loss: 0.1366, Accuracy: 96.67%\n",
      "Epoch [198/200], Loss: 0.1386, Accuracy: 96.67%\n",
      "Epoch [199/200], Loss: 0.1361, Accuracy: 96.67%\n",
      "Epoch [200/200], Loss: 0.1335, Accuracy: 96.67%\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset Iris\n",
    "iris = load_iris()\n",
    "X = iris.data  # Características (features)\n",
    "y = iris.target  # Rótulos (labels)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Converter para tensores do PyTorch\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar DataLoader para treino\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Criar DataLoader para teste\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Definir o modelo\n",
    "input_size = X_train.shape[1]  # 4 características de entrada\n",
    "hidden_size = 16\n",
    "output_size = len(set(y))  # 3 classes (Setosa, Versicolor, Virginica)\n",
    "dataset_samples = [list(range(10))]  # Exemplo simples, substitua conforme necessário\n",
    "threshold = 0.5\n",
    "\n",
    "model = AdvancedMLP(input_size=input_size, hidden_size=hidden_size, output_size=output_size, dataset_samples=dataset_samples, threshold=threshold)\n",
    "\n",
    "# Definir a função de perda e o otimizador\n",
    "criterion = nn.CrossEntropyLoss()  # Para classificação\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Treinamento do modelo\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, reinforcement_score = model(inputs)\n",
    "        \n",
    "        # Calcular a perda\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calcular acurácia\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct_preds / total_samples\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Avaliar o modelo nos dados de teste\n",
    "model.eval()\n",
    "correct_preds = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        outputs, _ = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "test_accuracy = 100 * correct_preds / total_samples\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68573f31-2c1a-44cd-8849-ee06d17fcb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.1572, Accuracy: 24.63%\n",
      "Epoch [2/100], Loss: 1.7826, Accuracy: 52.12%\n",
      "Epoch [3/100], Loss: 1.3857, Accuracy: 68.48%\n",
      "Epoch [4/100], Loss: 1.0367, Accuracy: 77.31%\n",
      "Epoch [5/100], Loss: 0.7769, Accuracy: 83.92%\n",
      "Epoch [6/100], Loss: 0.6006, Accuracy: 86.99%\n",
      "Epoch [7/100], Loss: 0.4813, Accuracy: 89.35%\n",
      "Epoch [8/100], Loss: 0.3978, Accuracy: 91.86%\n",
      "Epoch [9/100], Loss: 0.3332, Accuracy: 93.39%\n",
      "Epoch [10/100], Loss: 0.2840, Accuracy: 94.85%\n",
      "Epoch [11/100], Loss: 0.2442, Accuracy: 95.82%\n",
      "Epoch [12/100], Loss: 0.2139, Accuracy: 96.10%\n",
      "Epoch [13/100], Loss: 0.1901, Accuracy: 96.38%\n",
      "Epoch [14/100], Loss: 0.1705, Accuracy: 96.87%\n",
      "Epoch [15/100], Loss: 0.1542, Accuracy: 97.29%\n",
      "Epoch [16/100], Loss: 0.1407, Accuracy: 97.49%\n",
      "Epoch [17/100], Loss: 0.1293, Accuracy: 97.77%\n",
      "Epoch [18/100], Loss: 0.1189, Accuracy: 97.98%\n",
      "Epoch [19/100], Loss: 0.1097, Accuracy: 98.19%\n",
      "Epoch [20/100], Loss: 0.1020, Accuracy: 98.19%\n",
      "Epoch [21/100], Loss: 0.0952, Accuracy: 98.40%\n",
      "Epoch [22/100], Loss: 0.0886, Accuracy: 98.61%\n",
      "Epoch [23/100], Loss: 0.0829, Accuracy: 98.61%\n",
      "Epoch [24/100], Loss: 0.0775, Accuracy: 98.68%\n",
      "Epoch [25/100], Loss: 0.0730, Accuracy: 98.75%\n",
      "Epoch [26/100], Loss: 0.0687, Accuracy: 98.75%\n",
      "Epoch [27/100], Loss: 0.0645, Accuracy: 99.03%\n",
      "Epoch [28/100], Loss: 0.0610, Accuracy: 99.10%\n",
      "Epoch [29/100], Loss: 0.0574, Accuracy: 99.16%\n",
      "Epoch [30/100], Loss: 0.0546, Accuracy: 99.23%\n",
      "Epoch [31/100], Loss: 0.0513, Accuracy: 99.37%\n",
      "Epoch [32/100], Loss: 0.0489, Accuracy: 99.44%\n",
      "Epoch [33/100], Loss: 0.0462, Accuracy: 99.58%\n",
      "Epoch [34/100], Loss: 0.0440, Accuracy: 99.51%\n",
      "Epoch [35/100], Loss: 0.0418, Accuracy: 99.58%\n",
      "Epoch [36/100], Loss: 0.0398, Accuracy: 99.58%\n",
      "Epoch [37/100], Loss: 0.0381, Accuracy: 99.58%\n",
      "Epoch [38/100], Loss: 0.0362, Accuracy: 99.65%\n",
      "Epoch [39/100], Loss: 0.0346, Accuracy: 99.72%\n",
      "Epoch [40/100], Loss: 0.0332, Accuracy: 99.72%\n",
      "Epoch [41/100], Loss: 0.0317, Accuracy: 99.79%\n",
      "Epoch [42/100], Loss: 0.0304, Accuracy: 99.79%\n",
      "Epoch [43/100], Loss: 0.0291, Accuracy: 99.79%\n",
      "Epoch [44/100], Loss: 0.0280, Accuracy: 99.86%\n",
      "Epoch [45/100], Loss: 0.0266, Accuracy: 99.79%\n",
      "Epoch [46/100], Loss: 0.0256, Accuracy: 99.79%\n",
      "Epoch [47/100], Loss: 0.0245, Accuracy: 99.86%\n",
      "Epoch [48/100], Loss: 0.0236, Accuracy: 99.86%\n",
      "Epoch [49/100], Loss: 0.0225, Accuracy: 99.86%\n",
      "Epoch [50/100], Loss: 0.0217, Accuracy: 99.86%\n",
      "Epoch [51/100], Loss: 0.0208, Accuracy: 99.86%\n",
      "Epoch [52/100], Loss: 0.0202, Accuracy: 99.86%\n",
      "Epoch [53/100], Loss: 0.0192, Accuracy: 99.93%\n",
      "Epoch [54/100], Loss: 0.0185, Accuracy: 99.93%\n",
      "Epoch [55/100], Loss: 0.0177, Accuracy: 99.93%\n",
      "Epoch [56/100], Loss: 0.0170, Accuracy: 99.93%\n",
      "Epoch [57/100], Loss: 0.0165, Accuracy: 99.93%\n",
      "Epoch [58/100], Loss: 0.0158, Accuracy: 99.93%\n",
      "Epoch [59/100], Loss: 0.0152, Accuracy: 99.93%\n",
      "Epoch [60/100], Loss: 0.0146, Accuracy: 99.93%\n",
      "Epoch [61/100], Loss: 0.0141, Accuracy: 99.93%\n",
      "Epoch [62/100], Loss: 0.0135, Accuracy: 99.93%\n",
      "Epoch [63/100], Loss: 0.0130, Accuracy: 99.93%\n",
      "Epoch [64/100], Loss: 0.0125, Accuracy: 99.93%\n",
      "Epoch [65/100], Loss: 0.0120, Accuracy: 99.93%\n",
      "Epoch [66/100], Loss: 0.0117, Accuracy: 99.93%\n",
      "Epoch [67/100], Loss: 0.0111, Accuracy: 99.93%\n",
      "Epoch [68/100], Loss: 0.0107, Accuracy: 99.93%\n",
      "Epoch [69/100], Loss: 0.0103, Accuracy: 99.93%\n",
      "Epoch [70/100], Loss: 0.0099, Accuracy: 100.00%\n",
      "Epoch [71/100], Loss: 0.0096, Accuracy: 100.00%\n",
      "Epoch [72/100], Loss: 0.0092, Accuracy: 100.00%\n",
      "Epoch [73/100], Loss: 0.0090, Accuracy: 100.00%\n",
      "Epoch [74/100], Loss: 0.0086, Accuracy: 100.00%\n",
      "Epoch [75/100], Loss: 0.0083, Accuracy: 100.00%\n",
      "Epoch [76/100], Loss: 0.0080, Accuracy: 100.00%\n",
      "Epoch [77/100], Loss: 0.0077, Accuracy: 100.00%\n",
      "Epoch [78/100], Loss: 0.0074, Accuracy: 100.00%\n",
      "Epoch [79/100], Loss: 0.0072, Accuracy: 100.00%\n",
      "Epoch [80/100], Loss: 0.0069, Accuracy: 100.00%\n",
      "Epoch [81/100], Loss: 0.0067, Accuracy: 100.00%\n",
      "Epoch [82/100], Loss: 0.0065, Accuracy: 100.00%\n",
      "Epoch [83/100], Loss: 0.0063, Accuracy: 100.00%\n",
      "Epoch [84/100], Loss: 0.0060, Accuracy: 100.00%\n",
      "Epoch [85/100], Loss: 0.0058, Accuracy: 100.00%\n",
      "Epoch [86/100], Loss: 0.0056, Accuracy: 100.00%\n",
      "Epoch [87/100], Loss: 0.0055, Accuracy: 100.00%\n",
      "Epoch [88/100], Loss: 0.0053, Accuracy: 100.00%\n",
      "Epoch [89/100], Loss: 0.0051, Accuracy: 100.00%\n",
      "Epoch [90/100], Loss: 0.0049, Accuracy: 100.00%\n",
      "Epoch [91/100], Loss: 0.0048, Accuracy: 100.00%\n",
      "Epoch [92/100], Loss: 0.0046, Accuracy: 100.00%\n",
      "Epoch [93/100], Loss: 0.0045, Accuracy: 100.00%\n",
      "Epoch [94/100], Loss: 0.0043, Accuracy: 100.00%\n",
      "Epoch [95/100], Loss: 0.0042, Accuracy: 100.00%\n",
      "Epoch [96/100], Loss: 0.0041, Accuracy: 100.00%\n",
      "Epoch [97/100], Loss: 0.0040, Accuracy: 100.00%\n",
      "Epoch [98/100], Loss: 0.0038, Accuracy: 100.00%\n",
      "Epoch [99/100], Loss: 0.0037, Accuracy: 100.00%\n",
      "Epoch [100/100], Loss: 0.0036, Accuracy: 100.00%\n",
      "Test Accuracy: 97.22%\n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset Iris\n",
    "digits = load_digits()\n",
    "X = digits.data  # Características (features)\n",
    "y = digits.target  # Rótulos (labels)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Converter para tensores do PyTorch\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar DataLoader para treino\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Criar DataLoader para teste\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Definir o modelo\n",
    "input_size = X_train.shape[1]  # 4 características de entrada\n",
    "hidden_size = 16\n",
    "output_size = len(set(y))  # 3 classes (Setosa, Versicolor, Virginica)\n",
    "dataset_samples = [list(range(10))]  # Exemplo simples, substitua conforme necessário\n",
    "threshold = 0.5\n",
    "\n",
    "model = AdvancedMLP(input_size=input_size, hidden_size=hidden_size, output_size=output_size, dataset_samples=dataset_samples, threshold=threshold)\n",
    "\n",
    "# Definir a função de perda e o otimizador\n",
    "criterion = nn.CrossEntropyLoss()  # Para classificação\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Treinamento do modelo\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, reinforcement_score = model(inputs)\n",
    "        \n",
    "        # Calcular a perda\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calcular acurácia\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct_preds / total_samples\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Avaliar o modelo nos dados de teste\n",
    "model.eval()\n",
    "correct_preds = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        outputs, _ = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "test_accuracy = 100 * correct_preds / total_samples\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1ebcb-c226-4768-8fd3-e7867f46d5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5de74-3b77-4207-bfb8-be22253395db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
